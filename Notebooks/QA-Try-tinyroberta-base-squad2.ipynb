{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6056d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "import pickle\n",
    "import pdfplumber\n",
    "import torch\n",
    "import wikipedia as wiki\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0bc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(directory):\n",
    "    all_text = ''\n",
    "    with pdfplumber.open(directory) as pdf:\n",
    "            for pdf_page in pdf.pages:\n",
    "                single_page_text = pdf_page.extract_text()\n",
    "                all_text = all_text + '\\n' + single_page_text\n",
    "        \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4ad129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/tinyroberta-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ecf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = open(\"question_answering_tinyroberta_base.pkl\",\"wb\")\n",
    "pickle.dump(nlp, pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63051aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts before summarization: 42650\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word counts before summarization: {len(context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad2ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'pdf/Online learning and its problems in the Covid-19 emergency period.pdf'\n",
    "context = extract_pdf(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cae83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how many student were able to understand the material very well\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14f3630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:703: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "F:\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:297: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    }
   ],
   "source": [
    "res = nlp(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5d4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 74.2%\n",
      "Score: 0.8702821135520935\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", res['answer'])\n",
    "print(\"Score:\", res['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd394cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.7904082536697388, 'start': 8534, 'end': 8540, 'answer': '33.51%'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269db3ef",
   "metadata": {},
   "source": [
    "## ========================== SEPARATE ========================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d07607",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"question_answering_roberta_base.pkl\",\"rb\")\n",
    "model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e825ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'pdf/Online learning and its problems in the Covid-19 emergency period.pdf'\n",
    "context = extract_pdf(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4eaaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how many students learn material well\"\n",
    "result = model(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd89ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5022027492523193, 'start': 8833, 'end': 8839, 'answer': '45.56%'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2fe5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 45.56%\n",
      "Score: 0.5022027492523193\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Score:\", result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948db59",
   "metadata": {},
   "source": [
    "## ======================= SEPARATE ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7911679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "550832c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_2= pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f20e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is covid-19\" \n",
    "\n",
    "result = nlp_2(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32df7893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9946262240409851,\n",
       " 'start': 42389,\n",
       " 'end': 42410,\n",
       " 'answer': 'Corona virus diseases'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1203483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
